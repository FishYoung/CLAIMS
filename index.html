<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>CLAIMS by dase</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">CLAIMS</h1>
        <p class="header">Loong (previously called CLAIMS) is an In-memory parallel database prototype, which runs on a cluster of commodity servers and provides real-time interactive data analysis over relational dataset.</p>

        <ul>
          <li class="download"><a class="buttons" href="https://github.com/dase/Claims/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/dase/Claims/tarball/master">Download TAR</a></li>
          <li><a class="buttons github" href="https://github.com/dase/Claims">View On GitHub</a></li>
        </ul>

        <p class="header">This project is maintained by <a class="header name" href="https://github.com/dase">dase</a></p>


      </header>
      <section>
        <h1>
<a name="highlights" class="anchor" href="#highlights"><span class="octicon octicon-link"></span></a>Highlights</h1>

<h2>
<a name="1-massively-parallel-execution-engine" class="anchor" href="#1-massively-parallel-execution-engine"><span class="octicon octicon-link"></span></a>1. <strong>Massively parallel execution engine</strong>.</h2>

<p>Loong relies on highly parallel query processing engine to dramatically accelerate data analysis speed. Query evaluations are distributed across the cluster and executed in parallel. Even if on each node which constructs a mini-network (e.g., multi-processor, multi-core, NUMA), queries are evaluated in a multi-thread fashion to leverage the computation power of multi-core hardware. </p>

<h2>
<a name="2-smart-intra-node-parallelism" class="anchor" href="#2-smart-intra-node-parallelism"><span class="octicon octicon-link"></span></a>2. <strong>Smart intra-node parallelism</strong>.</h2>

<p>Pipelining the query execution among the clusters could effectively improve the query respond time but its benefits will be discounted if the workloads among execution fragments are imbalanced due to the improper intra-node parallelism. To tackle this problem, a novel elastic pipelining is proposed in CLAIMS to automatically adjust the intra-node parallelism of each query according to the runtime workload. Thanks to elastic pipelining, execution fragments which are detected to the performance bottleneck of the whole query will be given more parallelism to accelerate the data processing, while the parallelism of execution fragments that are detected to be over-producing will be decreased to avoid unnecessary computation allocation. </p>

<p>Pipelining the query execution among nodes in the cluster effectively reduces the response latency and dramatically saves storage space for intermediate query results. However, its benefits degrade tremendously when the workloads are imbalanced among execution partitions due to the improperly generated query execution plan. To tackle this problem, a novel elastic pipelining query processing model is proposed in Loong, which adapts the intra-node parallelism to the runtime workload. Beneficial from elastic pipelining query processing, the parallelism of different execution fragments in a pipelined is self-adaptive with each other and results in an optimal intra-node parallelism assignment.</p>

<h2>
<a name="3-efficient-in-memory-data-processing" class="anchor" href="#3-efficient-in-memory-data-processing"><span class="octicon octicon-link"></span></a>3. <strong>Efficient in-memory data processing</strong>.</h2>

<p>Loong employs a large set of optimization techniques to achieve efficient in-memory data processing, including batch-at-a-time processing, cache-sensitive operators, SIMD-based optimization, code generation, lock-free and concurrent processing structures. These optimizations collaborate together and enable Loong to process up to gigabytes data per second within a single thread.</p>

<h2>
<a name="4-network-communication-optimization" class="anchor" href="#4-network-communication-optimization"><span class="octicon octicon-link"></span></a>4. <strong>Network communication optimization</strong>.</h2>

<p>Parallel query processing imposes high burdens on network communication, which becomes the performance bottleneck for in-memory parallel databases due to the relatively slow network bandwidth comparing to the efficient in-memory data processing throughput. When compiling a user query into an execution plan, Loong’s query optimizer leverages a sophisticated selectivity propagation system and cost model to generate physical query plans with minimized network communication cost. Furthermore, Loong deploys a new data exchange implementation, which offers efficient, scalable and skew-resilient network data communication among Loong instances. These optimizations greatly reduce the response time of the queries that require network data communication.</p>

<h1>
<a name="team-members" class="anchor" href="#team-members"><span class="octicon octicon-link"></span></a>Team members</h1>

<p><a href="http://case.ecnu.edu.cn">Aoying Zhou</a>, a professor in East China Normal University, is the person in charge of this project.</p>

<p><a href="https://github.com/polpo1980">Minqi Zhou</a>, an associate professor in East China Normal University, is the person in charge of this project.</p>

<p><a href="https://github.com/wangli1426">Li Wang</a>, a Ph.D. student in East China Normal University, manages the master students in this team and is responsible for designing and implementing the key components of Loong, including query optimizer, catalog, physical operators, distributed communication infrastructure, storage layout, etc.</p>

<p><a href="https://github.com/egraldlo">Lei Zhang</a> is responsible for designing and implementing the key components of Loong, including query optimizer, physical operators, persistent data exchange, storage management, etc.</p>

<p><a href="https://github.com/scdong">Shaochan Dong</a> is responsible for designing and implementing in-memory index and index management, data types, as well as data loading and importing.</p>

<p><a href="">Xinzhou Zhang</a> is mainly responsible for web UI design and implementing data importing model.</p>

<p><a href="https://github.com/fzhedu">Zhuhe Fang</a> is mainly responsible for designing and implementing SQL DML parser and physical operators.</p>

<p><a href="https://github.com/yukai2014">Yu Kai</a> is mainly responsible for designing and implementing SQL DDL parser, catalog persistence.</p>

<p><a href="https://github.com/NagamineLee">Yongfeng Li</a> was a formal member of CLAIMS, who participated in designing and implementing catalog model.</p>

<p><a href="">Lin Gu</a> is responsible for designing the demo cases of CLAIMS.</p>

<h1>
<a name="publications" class="anchor" href="#publications"><span class="octicon octicon-link"></span></a>Publications</h1>

<ol>
<li>Li Wang, Minqi Zhou, Zhenjie Zhang, Yin Yang, Ming-chien Shan, Aoying Zhou. Elastic Pipelining in In-Memory Database Cluster. Submitted to SIGMOD 2015.</li>
<li>Li Wang, Minqi Zhou, Zhenjie Zhang, Ming-chien Shan, Aoying Zhou. NUMA-aware Scalable and Efficient Aggregation on Large Domains. Accepted by TKDE.</li>
<li>Li Wang, Lei Zhang, Chengcheng Yu, Aoying Zhou. Optimizing Pipelined Execution for Distributed In-memory OLAY System. In: DaMen 2014. Springer. 2014. pp. 35-56.</li>
<li>Lan Huang, Ke Xun, Xiaozhou Chen, Minqi Zhou, In-memory Cluster Computing: Interactive Data Analysis, Journal of East China Normal University, 2014</li>
<li>Shaochan Dong, Minqi Zhou, Rong Zhang，Aoying Zhou, In-Memory Index：Performance Enhancement Leveraging on Processors, Journal of East China Normal University,2014</li>
<li>Xinzhou Zhang, Minqi Zhou,A Survey of Fault Tolerance and Fault Recovery Technique in Large Distributed Parallel Computing System, Journal of East China Normal University,2014</li>
<li>Lei Zhang, Minqi Zhou, Li Wang, LCDJ: Locality Conscious Join Alogrithm for In-memory Cluster Computing, Journal of East China Normal University, 2014</li>
<li>Lei Zhang, Zhuhe Fang, Minqi Zhou，Lan Huang, Join Algorithms Towards In-memory Computing, Journal of East China Normal University, 2014</li>
<li>Yongfeng Li, Minqi Zhou, Hualiang Hu, Survey of resource uniform management and scheduling in cluster, Journal of East China Normal University, 2014</li>
</ol><h1>
<a name="setup-steps" class="anchor" href="#setup-steps"><span class="octicon octicon-link"></span></a>setup steps:</h1>

<pre><code>1. ./build.sh init
2. configure --prefix=/your/install/path 
3. make
4. make install
</code></pre>

<h1>
<a name="cleanup-steps" class="anchor" href="#cleanup-steps"><span class="octicon octicon-link"></span></a>cleanup steps:</h1>

<pre><code>1. make distclean
1. build.sh clean
</code></pre>
      </section>
      <footer>
        <p><small>Hosted on <a href="http://pages.github.com">GitHub Pages</a> using the Dinky theme</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
		
  </body>
</html>
